{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant libraries and functions\n",
    "from __future__ import print_function\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import numpy as np, h5py\n",
    "import os, time, sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Convolution2D, Input, SpatialDropout2D, UpSampling2D, MaxPooling2D, concatenate\n",
    "#from keras.layers.core import Activation, Laye#\n",
    "from keras.layers import Activation, Layer\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv2D, add, Conv3D, Reshape\n",
    "from keras.callbacks import History, EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from itertools import cycle\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.backend import set_session\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, SeparableConv2D, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7b5c26c83280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Save values to respective mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtpsfD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sigD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "#f_data = '.../trainData' # Directory with trainging data\n",
    "\n",
    "stacks = os.listdir(f_data)\n",
    "numS = int(len(stacks))\n",
    "\n",
    "nTG = 160 # Number of time-points\n",
    "xX = 28\n",
    "yY = 28\n",
    "\n",
    "tpsfD = np.ndarray(\n",
    "        (numS, int(nTG), int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "t1 = np.ndarray(\n",
    "        (numS, int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "t2 = np.ndarray(\n",
    "        (numS, int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "tR = np.ndarray(\n",
    "        (numS, int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "\n",
    "i = 0;\n",
    "for d in stacks:\n",
    "    # Save values to respective mapping\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    tpsfD[i,:,:,:,0] = f.get('sigD')\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    t1[i,:,:,0] = f.get('t1')\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    t2[i,:,:,0] = f.get('t2')\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    tR[i,:,:,0] = f.get('rT')\n",
    "    i = i + 1\n",
    "    \n",
    "tpsfD =  np.moveaxis(tpsfD, 1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure TPSF voxel shape is correct dimensionality (# samples, x, y, time-points, 1)\n",
    "tpsfD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant resblock functions (Keras API)\n",
    "def resblock_2D(num_filters, size_filter, x):\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    output = add([Fx, x])\n",
    "    output = Activation('relu')(output)\n",
    "    return output\n",
    "\n",
    "def resblock_2D_BN(num_filters, size_filter, x):\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    output = add([Fx, x])\n",
    "    #output = BatchNormalization()(output)\n",
    "    output = Activation('relu')(output)\n",
    "    return output\n",
    "\n",
    "def resblock_3D_BN(num_filters, size_filter, x):\n",
    "    Fx = Conv3D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = Conv3D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    output = add([Fx, x])\n",
    "    #output = BatchNormalization()(output)\n",
    "    output = Activation('relu')(output)\n",
    "    return output\n",
    "\n",
    "def xCeptionblock_2D_BN(num_filters, size_filter, x):\n",
    "    Fx = SeparableConv2D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = SeparableConv2D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    output = add([Fx, x])\n",
    "    output = Activation('relu')(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelD = None\n",
    "xX = 28;\n",
    "yY = 28;\n",
    "\n",
    "t_data = Input(shape=(xX, yY, 160,1))\n",
    "tpsf = t_data\n",
    "\n",
    "# # # # # # # # 3D-Model # # # # # # # #\n",
    "\n",
    "tpsf = Conv3D(50,kernel_size=(1,1,10),strides=(1,1,5), padding='same', activation=None, data_format=\"channels_last\")(tpsf)\n",
    "tpsf = BatchNormalization()(tpsf)\n",
    "tpsf = Activation('relu')(tpsf)\n",
    "tpsf = resblock_3D_BN(50, (1,1,5), tpsf)\n",
    "tpsf = Reshape((xX,yY,1600))(tpsf)\n",
    "tpsf = Conv2D(256, 1, padding='same', activation=None, data_format=\"channels_last\")(tpsf)\n",
    "tpsf = BatchNormalization()(tpsf)\n",
    "tpsf = Activation('relu')(tpsf)\n",
    "tpsf = Conv2D(256, 1, padding='same', activation=None, data_format=\"channels_last\")(tpsf)\n",
    "tpsf = BatchNormalization()(tpsf)\n",
    "tpsf = Activation('relu')(tpsf)\n",
    "tpsf = resblock_2D_BN(256, 1, tpsf)\n",
    "tpsf = resblock_2D_BN(256, 1, tpsf)\n",
    "\n",
    "# Short-lifetime branch\n",
    "imgT1 = Conv2D(64, 1, padding='same', activation=None)(tpsf)\n",
    "imgT1 = BatchNormalization()(imgT1)\n",
    "imgT1 = Activation('relu')(imgT1)\n",
    "imgT1 = Conv2D(32, 1, padding='same', activation=None)(imgT1)\n",
    "imgT1 = BatchNormalization()(imgT1)\n",
    "imgT1 = Activation('relu')(imgT1)\n",
    "imgT1 = Conv2D(1, 1, padding='same', activation=None)(imgT1)\n",
    "imgT1 = Activation('relu')(imgT1)\n",
    "\n",
    "# Long-lifetime branch\n",
    "imgT2 = Conv2D(64, 1, padding='same', activation=None)(tpsf)\n",
    "imgT2 = BatchNormalization()(imgT2)\n",
    "imgT2 = Activation('relu')(imgT2)\n",
    "imgT2 = Conv2D(32, 1, padding='same', activation=None)(imgT2)\n",
    "imgT2 = BatchNormalization()(imgT2)\n",
    "imgT2 = Activation('relu')(imgT2)\n",
    "imgT2 = Conv2D(1, 1, padding='same', activation=None)(imgT2)\n",
    "imgT2 = Activation('relu')(imgT2)\n",
    "\n",
    "# Amplitude-Ratio branch\n",
    "imgTR = Conv2D(64, 1, padding='same', activation=None)(tpsf)\n",
    "imgTR = BatchNormalization()(imgTR)\n",
    "imgTR = Activation('relu')(imgTR)\n",
    "imgTR = Conv2D(32, 1, padding='same', activation=None)(imgTR)\n",
    "imgTR = BatchNormalization()(imgTR)\n",
    "imgTR = Activation('relu')(imgTR)\n",
    "imgTR = Conv2D(1, 1, padding='same', activation=None)(imgTR)\n",
    "imgTR = Activation('relu')(imgTR)\n",
    "\n",
    "modelD = Model(inputs=[t_data], outputs=[imgT1,imgT2, imgTR])\n",
    "rmsprop = RMSprop(lr=1e-5)\n",
    "\n",
    "modelD.compile(loss='mse',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting patience (patience = 15 recommended)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience = 15, \n",
    "                              verbose = 0,\n",
    "                              mode = 'auto')\n",
    "\n",
    "fN = 'testName' # Assign some name for weights and training/validation loss curves here\n",
    "\n",
    "# Save loss curve (mse) and MAE information over all trained epochs. (monitor = '' can be changed to focus on other tau parameters)\n",
    "modelCheckPoint = ModelCheckpoint(filepath=fN+'.h5', \n",
    "                                  monitor='val_loss', \n",
    "                                  save_best_only=True, \n",
    "                                  verbose=0)\n",
    "# Train network (80/20 train/validation split, batch_size=20 recommended, nb_epoch may vary based on application)\n",
    "history = History()\n",
    "csv_logger = CSVLogger(fN+'.log')\n",
    "history = modelD.fit([tpsfD], [t1,t2,tR],\n",
    "          validation_split=0.2,\n",
    "          batch_size=20, nb_epoch=500, verbose=1, shuffle=True, callbacks=[earlyStopping,csv_logger,modelCheckPoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Post-training: load \"best\" trained weights (obtained through patience - lowest value of loss)\n",
    "# THIS CAN BE ANY WEIGHT FILE, AS LONG AS THE NETWORK ARCHITECTURE MATCHES THE ONE USED!\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "modelD.load_weights(fN+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload test data and use 3D-CNN for inference\n",
    "\n",
    "t_data = '.../testData' # directory with test data\n",
    "stacksT = os.listdir(f_data)\n",
    "numT = int(len(stacks))\n",
    "\n",
    "nTG = 160\n",
    "xX = 28\n",
    "yY = 28\n",
    "\n",
    "tpsfT = np.ndarray(\n",
    "        (numT, int(nTG), int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "t1T = np.ndarray(\n",
    "        (numT, int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "t2T = np.ndarray(\n",
    "        (numT, int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "tRT = np.ndarray(\n",
    "        (numT, int(xX), int(yY), int(1)), dtype=np.float32\n",
    "        )\n",
    "\n",
    "i = 0;\n",
    "for d in stacksT:\n",
    "    # Save values to respective mapping\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    tpsfT[i,:,:,:,0] = f.get('sigD')\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    t1T[i,:,:,0] = f.get('t1')\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    t2T[i,:,:,0] = f.get('t2')\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    tRT[i,:,:,0] = f.get('rT')\n",
    "    i = i + 1\n",
    "    \n",
    "tpsfT =  np.moveaxis(tpsfT, 1, -2)\n",
    "# tpsfT = np.moveaxis(tpsfT, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on test data with trained model\n",
    "testV = modelD.predict(tpsfT)\n",
    "t1P = testV[0] # Predicted t1 values\n",
    "t2P = testV[1] # Predicted t2 values\n",
    "tRP = testV[2] # Predicted AR values\n",
    "\n",
    "# Visualize example\n",
    "n = 2 # Number to illustrate w/ matplotlib\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(3,2,1)\n",
    "# Predicted tau1\n",
    "ax1.imshow(t1P[n,:,:,0], interpolation='nearest', vmin=.2, vmax=.6)\n",
    "ax2 = fig.add_subplot(3,2,2)\n",
    "# G.T. tau1\n",
    "ax2.imshow(t1T[n,:,:,0], interpolation='nearest', vmin=.2, vmax=.6)\n",
    "ax3 = fig.add_subplot(3,2,3)\n",
    "# Predicted tau2\n",
    "ax3.imshow(t2P[n,:,:,0], interpolation='nearest', vmin=0.8, vmax=1.5)\n",
    "# G.T. tau2\n",
    "ax4 = fig.add_subplot(3,2,4)\n",
    "ax4.imshow(t2T[n,:,:,0], interpolation='nearest', vmin=.8, vmax=1.5)\n",
    "# Predicted amplitude ratio\n",
    "ax5 = fig.add_subplot(3,2,5)\n",
    "ax5.imshow(tRP[n,:,:,0], interpolation='nearest', vmin=0, vmax=1)\n",
    "# G.T. amplitude ratio\n",
    "ax6 = fig.add_subplot(3,2,6)\n",
    "ax6.imshow(tRT[n,:,:,0], interpolation='nearest', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
